{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neccessary Packages to Install"
      ],
      "metadata": {
        "id": "GCvu36hk_B59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kvhAQYFE0VP",
        "outputId": "55f3b79f-e128-4ce7-ce05-a2e600ab544d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx2txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TOvCLlUE720",
        "outputId": "7acc91f3-3122-4df2-bebc-c920cd04bedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=04f8d3961b978afa04dc6c6fa394cfa93b200205251da101ba75dc8db3993c77\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anvil-uplink"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYFcoCEWFLmA",
        "outputId": "acbf3717-24f2-41c8-f9b6-41cb0486584e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.4.2-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/90.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argparse (from anvil-uplink)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.16.0)\n",
            "Collecting ws4py (from anvil-uplink)\n",
            "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45228 sha256=4b321c7d16ee777c44aebd2e4b0a798650c0be5159df36d552da8b7c3a9464ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/7c/ad/d9c746276bf024d44296340869fcb169f1e5d80fb147351a57\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.4.2 argparse-1.4.0 ws4py-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcYvkLQN-UWY",
        "outputId": "18b41ffe-1e3a-4dcf-8b2d-103e79ec6464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement io (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for io\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrrPjFoO_x2g",
        "outputId": "79a6dab0-7fd1-4938-8c71-7153e20bda2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from docx) (4.9.4)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.10/dist-packages (from docx) (9.4.0)\n",
            "Building wheels for collected packages: docx\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53895 sha256=d727d6e2014517eda8ec331e3d52c38e66c49f1dea97cf6184c3c6358461f1b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/f5/1d/e09ba2c1907a43a4146d1189ae4733ca1a3bfe27ee39507767\n",
            "Successfully built docx\n",
            "Installing collected packages: docx\n",
            "Successfully installed docx-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade python-docx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyuAn5x3FdlV",
        "outputId": "5ca13c4e-d188-47aa-bbd0-ec0f62d0701b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/239.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m194.6/239.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.0)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting to Anvil Server"
      ],
      "metadata": {
        "id": "qylR5bxA_O8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import anvil.server\n",
        "\n",
        "anvil.server.connect(\"server_ANF2KMKRSLLDKFZ7X3IBCTAE-6SY7YMMIXTLH7JKO\")"
      ],
      "metadata": {
        "id": "r5zy2I16FWaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63097aa3-36d0-4834-88e0-632b5ed4e9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default Environment\" as SERVER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neccessary Libraries"
      ],
      "metadata": {
        "id": "99yTDqgF_ids"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import anvil.media\n",
        "from anvil import server\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import PyPDF2\n",
        "import docx\n",
        "import re\n",
        "from io import BytesIO\n",
        "import spacy\n",
        "import re\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ],
      "metadata": {
        "id": "sFkbsFetE_aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling for Extraction of Name and Phone Number"
      ],
      "metadata": {
        "id": "NTfduLH1Cde6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_information(content):\n",
        "    name = extract_name(content)\n",
        "    phone_number = extract_phone_number(content)\n",
        "\n",
        "    return name, phone_number\n"
      ],
      "metadata": {
        "id": "G6WkQ3C4E_dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Name using Regular Expression"
      ],
      "metadata": {
        "id": "daojNU0iCRel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_name(content):\n",
        "    name_pattern = re.compile(r'(?i)\\b(?:mr|miss|mrs|ms|dr|prof|rev)\\.?\\s+([A-Z][a-z]+(?:-[A-Z][a-z]+)?)\\b')\n",
        "    name_match = name_pattern.search(content)\n",
        "\n",
        "    if name_match:\n",
        "        return name_match.group(1)\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "U9mYD1NK_srX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Phone Number from Resume using Regular Expression"
      ],
      "metadata": {
        "id": "LxY7-I5eCG-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_phone_number(content):\n",
        "    phone_number_match = re.search(r\"\\b(?:\\+\\d{1,2}\\s)?\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b\", content)\n",
        "    if phone_number_match:\n",
        "        return phone_number_match.group()\n",
        "    else:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "0kvy9HER_suo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Matched Skills"
      ],
      "metadata": {
        "id": "o_gz6t1qB6a1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_skills(content):\n",
        "    common_skills_list = [\n",
        "        \"python\", \"java\", \"javascript\", \"c++\", \"c#\", \"html\", \"css\", \"sql\",\n",
        "        \"git\", \"linux\", \"windows\", \"macos\", \"agile\", \"scrum\", \"kanban\",\n",
        "        \"docker\", \"aws\", \"azure\", \"google cloud\", \"tensorflow\", \"pytorch\",\n",
        "        \"keras\", \"pandas\", \"numpy\", \"matplotlib\", \"scikit-learn\", \"opencv\",\n",
        "        \"nlp\", \"machine learning\", \"deep learning\", \"data mining\", \"data analysis\",\n",
        "        \"data visualization\", \"statistics\", \"linear regression\", \"logistic regression\",\n",
        "        \"decision trees\", \"random forest\", \"gradient boosting\", \"svm\", \"neural networks\",\n",
        "        \"natural language processing\", \"computer vision\", \"image processing\", \"big data\",\n",
        "        \"hive\", \"spark\", \"hadoop\", \"mongodb\", \"postgresql\", \"mysql\", \"oracle\", \"sql server\",\n",
        "        \"azure devops\", \"jenkins\", \"gitlab\", \"jira\", \"confluence\", \"slack\", \"trello\", \"zoom\",\n",
        "        \"microsoft office\", \"word\", \"excel\", \"powerpoint\", \"outlook\", \"google workspace\",\n",
        "        \"docs\", \"sheets\", \"slides\", \"communication\", \"problem solving\", \"teamwork\",\n",
        "        \"leadership\", \"time management\", \"creativity\", \"adaptability\", \"attention to detail\",\n",
        "        \"critical thinking\", \"customer service\", \"sales\", \"marketing\", \"project management\",\n",
        "        \"business development\", \"financial analysis\", \"accounting\", \"human resources\",\n",
        "        \"recruiting\", \"strategic planning\", \"public speaking\", \"presentation skills\"\n",
        "    ]\n",
        "\n",
        "    escaped_skills = [re.escape(skill) for skill in common_skills_list]\n",
        "    skill_pattern = r\"\\b(?:{})\\b\".format(\"|\".join(escaped_skills))\n",
        "\n",
        "    skills_match = re.findall(skill_pattern, content, flags=re.IGNORECASE)\n",
        "\n",
        "    return skills_match"
      ],
      "metadata": {
        "id": "xXfCYPZo_sxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting the Keywords"
      ],
      "metadata": {
        "id": "Y40oETR1BVwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords(text):\n",
        "    keywords = [\n",
        "        \"experience\", \"skills\", \"education\", \"achievements\",\n",
        "        \"work history\", \"employment history\", \"professional experience\",\n",
        "        \"technical skills\", \"soft skills\", \"qualifications\",\n",
        "        \"certifications\", \"training\", \"courses\", \"projects\",\n",
        "        \"languages\", \"tools\", \"technologies\", \"frameworks\",\n",
        "        \"industry knowledge\", \"awards\", \"honors\", \"publications\",\n",
        "        \"presentations\", \"conferences\", \"volunteer experience\",\n",
        "        \"extracurricular activities\", \"leadership\", \"teamwork\",\n",
        "        \"communication skills\", \"problem solving\", \"adaptability\",\n",
        "        \"attention to detail\", \"creativity\", \"analytical skills\",\n",
        "        \"customer service\", \"sales\", \"marketing\", \"management\",\n",
        "        \"project management\", \"collaboration\", \"time management\",\n",
        "        \"interpersonal skills\", \"negotiation\", \"conflict resolution\",\n",
        "        \"decision making\", \"innovation\", \"strategic planning\"\n",
        "    ]\n",
        "\n",
        "    extracted_keywords = []\n",
        "    for keyword in keywords:\n",
        "        if keyword.lower() in text.lower():\n",
        "            extracted_keywords.append(keyword)\n",
        "\n",
        "    return extracted_keywords\n"
      ],
      "metadata": {
        "id": "_JiQ7YIk_s2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use spaCy for Named Entity Recognition (NER)"
      ],
      "metadata": {
        "id": "0e2CRiPEBRtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_entities(text):\n",
        "\n",
        "    doc = nlp(text)\n",
        "    entities = [ent.text for ent in doc.ents]\n",
        "    return entities"
      ],
      "metadata": {
        "id": "9jirccBZ_s50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the content of the .docx file"
      ],
      "metadata": {
        "id": "Ric_XNY-BN3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_docx(file):\n",
        "    try:\n",
        "        docx_content = file.get_bytes().decode(\"utf-8\")  # Try decoding with UTF-8\n",
        "    except UnicodeDecodeError:\n",
        "        docx_content = file.get_bytes().decode(\"latin1\")  # Fallback to Latin-1 encoding\n",
        "    return docx_content\n"
      ],
      "metadata": {
        "id": "Zf3g7RfbAXq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the content of the PDF file using PyPDF2"
      ],
      "metadata": {
        "id": "KLuaNLJ6BKPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_pdf(file):\n",
        "    pdf_bytes = BytesIO(file.get_bytes())\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_bytes)\n",
        "    pdf_text = \"\"\n",
        "    for page_num in range(len(pdf_reader.pages)):\n",
        "        page = pdf_reader.pages[page_num]\n",
        "        pdf_text += page.extract_text()\n",
        "    return pdf_text"
      ],
      "metadata": {
        "id": "wc1MK96_AXm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting E-Mail using Regular Expression"
      ],
      "metadata": {
        "id": "NCJvbCZDCm3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_email(content):\n",
        "    email_pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"  #Regular Expression for E-mail extraction\n",
        "    email_match = re.search(email_pattern, content)\n",
        "    if email_match:\n",
        "        return email_match.group()\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "3ZHuiJDZAXlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Function"
      ],
      "metadata": {
        "id": "-PxxVKsiCwma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@server.callable\n",
        "def compare_docs(file1, file2):\n",
        "    if file1.name.lower().endswith('.pdf'):\n",
        "        doc1_content = read_pdf(file1)\n",
        "    else:\n",
        "        doc1_content = read_docx(file1)\n",
        "\n",
        "    if file2.name.lower().endswith('.pdf'):\n",
        "        doc2_content = read_pdf(file2)\n",
        "    else:\n",
        "        doc2_content = read_docx(file2)\n",
        "\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform([doc1_content, doc2_content])\n",
        "\n",
        "    similarity_score = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0] #Finding Cossimilarity\n",
        "\n",
        "    keywords1 = extract_keywords(doc1_content)\n",
        "    keywords2 = extract_keywords(doc2_content)\n",
        "\n",
        "    entities1 = extract_entities(doc1_content)\n",
        "    entities2 = extract_entities(doc2_content)\n",
        "    skill1 = extract_skills(doc1_content)\n",
        "    skills2 = extract_skills(doc2_content)\n",
        "\n",
        "    skills1 = list(set(skill1).intersection(set(skills2)))\n",
        "    email1=extract_email(doc1_content)\n",
        "\n",
        "    name1, phone_number1 = extract_information(doc1_content)\n",
        "\n",
        "    keyword_match = len(set(keywords1).intersection(set(keywords2)))\n",
        "    entity_match = len(set(entities1).intersection(set(entities2)))\n",
        "\n",
        "    return similarity_score, keyword_match, entity_match, name1, phone_number1, skills1,email1\n"
      ],
      "metadata": {
        "id": "MFkPJ1bVE_gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BDfi7zDqF7Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKZaKuVxMN9Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}